{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../EDA/dataframe_model/stretchedSociety_block_109_MAC005547.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Energy_kwh</th>\n",
       "      <th>house_hold</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>precipType</th>\n",
       "      <th>icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>holiday</th>\n",
       "      <th>bool_weather_missing_values</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0</td>\n",
       "      <td>7.01</td>\n",
       "      <td>5.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0</td>\n",
       "      <td>7.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0</td>\n",
       "      <td>6.29</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  Energy_kwh  house_hold  temperature  windSpeed  \\\n",
       "0  2013-01-01 00:00:00       0.497           0         7.01       5.46   \n",
       "1  2013-01-01 01:00:00       0.314           0         7.49       5.51   \n",
       "2  2013-01-01 02:00:00       0.202           0         7.16       5.74   \n",
       "3  2013-01-01 03:00:00       0.171           0         7.04       4.98   \n",
       "4  2013-01-01 04:00:00       0.185           0         6.29       4.20   \n",
       "\n",
       "   precipType  icon  summary  holiday  bool_weather_missing_values  year  \\\n",
       "0           0     0        0        1                            0     0   \n",
       "1           0     0        0        0                            0     0   \n",
       "2           0     0        0        0                            0     0   \n",
       "3           0     0        0        0                            0     0   \n",
       "4           0     0        0        0                            0     0   \n",
       "\n",
       "   month  day  hour  dayofweek_num  \n",
       "0      0    0     0              0  \n",
       "1      0    0     1              0  \n",
       "2      0    0     2              0  \n",
       "3      0    0     3              0  \n",
       "4      0    0     4              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10153 entries, 0 to 10152\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   time           10153 non-null  datetime64[ns]\n",
      " 1   Energy_kwh     10153 non-null  float64       \n",
      " 2   holiday        10153 non-null  int64         \n",
      " 3   month          10153 non-null  int64         \n",
      " 4   hour           10153 non-null  int64         \n",
      " 5   dayofweek_num  10153 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4)\n",
      "memory usage: 476.0 KB\n"
     ]
    }
   ],
   "source": [
    "df[['time','Energy_kwh','holiday','month','hour','dayofweek_num']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['time','Energy_kwh','holiday','month','hour','dayofweek_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:26:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:26:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados salvos em 'prophet_results.csv'\n",
      "     model       mae      mape     smape      rmse  training_time\n",
      "0  Prophet  0.117594  0.464684  0.366027  0.152383       0.819523\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Função para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# Função para calcular SMAPE\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Preparar os dados\n",
    "df_prophet = df.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = len(df) - 168\n",
    "df_train = df_prophet[:train_size]\n",
    "df_test = df_prophet[train_size:]\n",
    "\n",
    "# Criar e treinar o modelo Prophet\n",
    "start_time = time.time()\n",
    "\n",
    "model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
    "model.add_regressor('holiday')\n",
    "model.add_regressor('month')\n",
    "model.add_regressor('hour')\n",
    "model.add_regressor('dayofweek_num')\n",
    "\n",
    "model.fit(df_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Fazer previsões\n",
    "future = df_test[['ds', 'holiday', 'month', 'hour', 'dayofweek_num']]\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Calcular métricas\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat'].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Salvar resultados em CSV\n",
    "results = pd.DataFrame({\n",
    "    'model': ['Prophet'],\n",
    "    'mae': [mae],\n",
    "    'mape': [mape],\n",
    "    'smape': [smape],\n",
    "    'rmse': [rmse],\n",
    "    'training_time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('prophet_results.csv', index=False)\n",
    "\n",
    "print(\"Resultados salvos em 'prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Função para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Função para calcular SMAPE\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Preparar os dados\n",
    "df_sarimax = df.set_index('time')\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = len(df) - 168\n",
    "df_train = df_sarimax[:train_size]\n",
    "df_test = df_sarimax[train_size:]\n",
    "\n",
    "# Definir variáveis exógenas\n",
    "exog_vars = ['holiday', 'month', 'hour', 'dayofweek_num']\n",
    "\n",
    "# Criar e treinar o modelo SARIMAX\n",
    "start_time = time.time()\n",
    "\n",
    "# Aqui, estamos usando um modelo SARIMAX(1,1,1)(1,1,1,24) como exemplo\n",
    "# Você pode ajustar esses parâmetros conforme necessário\n",
    "model = SARIMAX(df_train['Energy_kwh'], \n",
    "                exog=df_train[exog_vars],\n",
    "                order=(1, 1, 1),\n",
    "                seasonal_order=(1, 1, 1, 24),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Fazer previsões\n",
    "forecast = results.get_forecast(steps=168, exog=df_test[exog_vars])\n",
    "y_pred = forecast.predicted_mean\n",
    "\n",
    "# Calcular métricas\n",
    "y_true = df_test['Energy_kwh'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Salvar resultados em CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'model': ['SARIMAX'],\n",
    "    'mae': [mae],\n",
    "    'mape': [mape],\n",
    "    'smape': [smape],\n",
    "    'rmse': [rmse],\n",
    "    'training_time': [training_time]\n",
    "})\n",
    "\n",
    "results_df.to_csv('sarimax_results.csv', index=False)\n",
    "\n",
    "print(\"Resultados salvos em 'sarimax_results.csv'\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Preparação dos dados\n",
      "                    ds      y  holiday  month  hour  dayofweek_num\n",
      "0  2013-01-01 00:00:00  0.497        1      0     0              0\n",
      "1  2013-01-01 01:00:00  0.314        0      0     1              0\n",
      "2  2013-01-01 02:00:00  0.202        0      0     2              0\n",
      "3  2013-01-01 03:00:00  0.171        0      0     3              0\n",
      "4  2013-01-01 04:00:00  0.185        0      0     4              0\n",
      "Shape dos dados: (10153, 6)\n",
      "\n",
      "Passo 2: Divisão dos dados\n",
      "Shape do conjunto de treino: (9985, 6)\n",
      "Shape do conjunto de teste: (168, 6)\n",
      "\n",
      "Passo 3: Configuração do modelo Neural Prophet\n",
      "\n",
      "Passo 4: Treinamento do modelo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b426c6e1abf4c03bd071fb9bf23ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (157) is too small than the required number                     for the learning rate finder (250). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebc8717156f46efb042430998b26f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7bcddd41cc40ceb6563785463d5b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 129.06 segundos\n",
      "\n",
      "Passo 5: Fazendo previsões\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa27e415087c4d0da63f3cc471ca1c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds      y     yhat1     trend  season_yearly  \\\n",
      "0 2014-02-21 01:00:00  0.555  0.307385  0.334974       0.059196   \n",
      "1 2014-02-21 02:00:00  0.588  0.226512  0.334983       0.059258   \n",
      "2 2014-02-21 03:00:00  0.398  0.195170  0.334993       0.059319   \n",
      "3 2014-02-21 04:00:00  0.163  0.183428  0.335002       0.059380   \n",
      "4 2014-02-21 05:00:00  0.159  0.181712  0.335012       0.059443   \n",
      "\n",
      "   season_weekly  season_daily  future_regressors_additive  \\\n",
      "0      -0.020100     -0.065280                   -0.001405   \n",
      "1      -0.019357     -0.146040                   -0.002332   \n",
      "2      -0.018531     -0.177351                   -0.003258   \n",
      "3      -0.017640     -0.189129                   -0.004185   \n",
      "4      -0.016663     -0.190968                   -0.005112   \n",
      "\n",
      "   future_regressor_dayofweek_num  future_regressor_holiday  \\\n",
      "0                       -0.005474                       0.0   \n",
      "1                       -0.005474                       0.0   \n",
      "2                       -0.005474                       0.0   \n",
      "3                       -0.005474                       0.0   \n",
      "4                       -0.005474                       0.0   \n",
      "\n",
      "   future_regressor_hour  future_regressor_month  \n",
      "0              -0.000927                0.004996  \n",
      "1              -0.001853                0.004996  \n",
      "2              -0.002780                0.004996  \n",
      "3              -0.003707                0.004996  \n",
      "4              -0.004633                0.004996  \n",
      "\n",
      "Passo 6: Cálculo das métricas\n",
      "\n",
      "Passo 7: Salvando resultados\n",
      "\n",
      "Resultados salvos em 'neural_prophet_results.csv'\n",
      "           Model       MAE      RMSE      MAPE      SMAPE  Training_Time\n",
      "0  NeuralProphet  0.119048  0.148566  51.55919  38.307913     129.062095\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Assumindo que df já está definido e contém os dados necessários\n",
    "\n",
    "# Passo 1: Preparação dos dados\n",
    "print(\"Passo 1: Preparação dos dados\")\n",
    "df_model = df[['time', 'Energy_kwh', 'holiday', 'month', 'hour', 'dayofweek_num']].copy()\n",
    "df_model = df_model.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "print(df_model.head())\n",
    "print(f\"Shape dos dados: {df_model.shape}\")\n",
    "\n",
    "# Passo 2: Definir o ponto de divisão para treinamento/teste\n",
    "print(\"\\nPasso 2: Divisão dos dados\")\n",
    "split_point = len(df_model) - 168\n",
    "df_train = df_model[:split_point]\n",
    "df_test = df_model[split_point:]\n",
    "print(f\"Shape do conjunto de treino: {df_train.shape}\")\n",
    "print(f\"Shape do conjunto de teste: {df_test.shape}\")\n",
    "\n",
    "# Passo 3: Configuração do modelo Neural Prophet\n",
    "print(\"\\nPasso 3: Configuração do modelo Neural Prophet\")\n",
    "model = NeuralProphet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Adicionar as covariáveis\n",
    "for regressor in ['holiday', 'month', 'hour', 'dayofweek_num']:\n",
    "    model.add_future_regressor(regressor)\n",
    "\n",
    "# Passo 4: Treinamento do modelo e medição do tempo\n",
    "print(\"\\nPasso 4: Treinamento do modelo\")\n",
    "start_time = time.time()\n",
    "metrics = model.fit(df_train, freq='H')\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Tempo de treinamento: {training_time:.2f} segundos\")\n",
    "\n",
    "# Passo 5: Fazer previsões\n",
    "print(\"\\nPasso 5: Fazendo previsões\")\n",
    "# Usamos df_test diretamente, pois já contém os valores futuros dos regressores\n",
    "forecast = model.predict(df_test)\n",
    "print(forecast.head())\n",
    "\n",
    "# Passo 6: Calcular métricas\n",
    "print(\"\\nPasso 6: Cálculo das métricas\")\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat1'].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "\n",
    "# Passo 7: Salvar resultados em CSV\n",
    "print(\"\\nPasso 7: Salvando resultados\")\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['NeuralProphet'],\n",
    "    'MAE': [mae],\n",
    "    'RMSE': [rmse],\n",
    "    'MAPE': [mape],\n",
    "    'SMAPE': [smape],\n",
    "    'Training_Time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('neural_prophet_results.csv', index=False)\n",
    "\n",
    "print(\"\\nResultados salvos em 'neural_prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as h\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Preparação dos dados\n",
      "                    ds      y  holiday  month  hour  dayofweek_num\n",
      "0  2013-01-01 00:00:00  0.497        1      0     0              0\n",
      "1  2013-01-01 01:00:00  0.314        0      0     1              0\n",
      "2  2013-01-01 02:00:00  0.202        0      0     2              0\n",
      "3  2013-01-01 03:00:00  0.171        0      0     3              0\n",
      "4  2013-01-01 04:00:00  0.185        0      0     4              0\n",
      "Shape dos dados: (10153, 6)\n",
      "\n",
      "Passo 2: Configuração do modelo Neural Prophet\n",
      "\n",
      "Passo 3: Divisão dos dados\n",
      "Shape do conjunto de treino: (9985, 6)\n",
      "Shape do conjunto de teste: (168, 6)\n",
      "\n",
      "Passo 4: Treinamento do modelo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c47a8668b8a4177bedcd4fed149982f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (157) is too small than the required number                     for the learning rate finder (250). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf18b7a7b944fa850a5a4350566707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bab6a442164b76a1fddee44b6eea15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 125.41 segundos\n",
      "\n",
      "Passo 5: Criando dataframe futuro e fazendo previsões\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:983: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_date, periods=periods + 1, freq=freq)  # An extra in case we include start\n",
      "\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4ab06f2f23433db0984b44199324b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds     y     yhat1     trend  season_yearly  season_weekly  \\\n",
      "0 2014-02-21 01:00:00  None  0.306050  0.385866       0.006615      -0.021134   \n",
      "1 2014-02-21 02:00:00  None  0.223760  0.385886       0.006683      -0.020446   \n",
      "2 2014-02-21 03:00:00  None  0.192097  0.385906       0.006749      -0.019680   \n",
      "3 2014-02-21 04:00:00  None  0.180905  0.385926       0.006817      -0.018834   \n",
      "4 2014-02-21 05:00:00  None  0.178642  0.385945       0.006884      -0.017909   \n",
      "\n",
      "   season_daily  future_regressors_additive  future_regressor_dayofweek_num  \\\n",
      "0     -0.063405                   -0.001891                       -0.005868   \n",
      "1     -0.145585                   -0.002777                       -0.005868   \n",
      "2     -0.177214                   -0.003664                       -0.005868   \n",
      "3     -0.188453                   -0.004550                       -0.005868   \n",
      "4     -0.190843                   -0.005436                       -0.005868   \n",
      "\n",
      "   future_regressor_holiday  future_regressor_hour  future_regressor_month  \n",
      "0                       0.0              -0.000886                0.004863  \n",
      "1                       0.0              -0.001772                0.004863  \n",
      "2                       0.0              -0.002658                0.004863  \n",
      "3                       0.0              -0.003544                0.004863  \n",
      "4                       0.0              -0.004430                0.004863  \n",
      "\n",
      "Passo 6: Cálculo das métricas\n",
      "\n",
      "Passo 7: Salvando resultados\n",
      "\n",
      "Resultados salvos em 'neural_prophet_results.csv'\n",
      "           Model       MAE      RMSE       MAPE      SMAPE  Training_Time\n",
      "0  NeuralProphet  0.119174  0.148845  51.449813  38.330516     125.410824\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Assumindo que df já está definido e contém os dados necessários\n",
    "\n",
    "# Passo 1: Preparação dos dados\n",
    "print(\"Passo 1: Preparação dos dados\")\n",
    "df_model = df[['time', 'Energy_kwh', 'holiday', 'month', 'hour', 'dayofweek_num']].copy()\n",
    "df_model = df_model.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "print(df_model.head())\n",
    "print(f\"Shape dos dados: {df_model.shape}\")\n",
    "\n",
    "# Passo 2: Configuração do modelo Neural Prophet\n",
    "print(\"\\nPasso 2: Configuração do modelo Neural Prophet\")\n",
    "model = NeuralProphet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Adicionar as covariáveis\n",
    "for regressor in ['holiday', 'month', 'hour', 'dayofweek_num']:\n",
    "    model.add_future_regressor(regressor)\n",
    "\n",
    "# Passo 3: Divisão dos dados usando split_df\n",
    "print(\"\\nPasso 3: Divisão dos dados\")\n",
    "df_train, df_test = model.split_df(df_model, valid_p=168/len(df_model))\n",
    "print(f\"Shape do conjunto de treino: {df_train.shape}\")\n",
    "print(f\"Shape do conjunto de teste: {df_test.shape}\")\n",
    "\n",
    "# Passo 4: Treinamento do modelo e medição do tempo\n",
    "print(\"\\nPasso 4: Treinamento do modelo\")\n",
    "start_time = time.time()\n",
    "metrics = model.fit(df_train, freq='H')\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Tempo de treinamento: {training_time:.2f} segundos\")\n",
    "\n",
    "# Passo 5: Criar dataframe futuro e fazer previsões\n",
    "print(\"\\nPasso 5: Criando dataframe futuro e fazendo previsões\")\n",
    "future_df = model.make_future_dataframe(df_train, periods=168, regressors_df=df_test)\n",
    "forecast = model.predict(future_df)\n",
    "print(forecast.head())\n",
    "\n",
    "# Passo 6: Calcular métricas\n",
    "print(\"\\nPasso 6: Cálculo das métricas\")\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat1'].values[:168]  # Pegamos apenas as primeiras 168 previsões\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "\n",
    "# Passo 7: Salvar resultados em CSV\n",
    "print(\"\\nPasso 7: Salvando resultados\")\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['NeuralProphet'],\n",
    "    'MAE': [mae],\n",
    "    'RMSE': [rmse],\n",
    "    'MAPE': [mape],\n",
    "    'SMAPE': [smape],\n",
    "    'Training_Time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('neural_prophet_results.csv', index=False)\n",
    "\n",
    "print(\"\\nResultados salvos em 'neural_prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = [\n",
    "    'establishedAffluence_block_10_MAC001221.csv',\n",
    "    'establishedAffluence_block_10_MAC001402.csv',\n",
    "    'establishedAffluence_block_10_MAC001869.csv',\n",
    "    'establishedAffluence_block_10_MAC002036.csv',\n",
    "    'establishedAffluence_block_11_MAC001980.csv',\n",
    "    'establishedAffluence_block_12_MAC002752.csv',\n",
    "    'establishedAffluence_block_13_MAC005411.csv',\n",
    "    'establishedAffluence_block_14_MAC002635.csv',\n",
    "    'establishedAffluence_block_17_MAC002007.csv',\n",
    "    'establishedAffluence_block_18_MAC005491.csv',\n",
    "    'establishedAffluence_block_19_MAC002250.csv',\n",
    "    'establishedAffluence_block_19_MAC005426.csv',\n",
    "    'establishedAffluence_block_19_MAC005566.csv',\n",
    "    'establishedAffluence_block_21_MAC004390.csv',\n",
    "    'establishedAffluence_block_21_MAC004531.csv',\n",
    "    'establishedAffluence_block_22_MAC004694.csv',\n",
    "    'establishedAffluence_block_22_MAC004736.csv',\n",
    "    'establishedAffluence_block_23_MAC000164.csv',\n",
    "    'establishedAffluence_block_23_MAC004618.csv',\n",
    "    'establishedAffluence_block_23_MAC004625.csv',\n",
    "    'establishedAffluence_block_25_MAC004233.csv',\n",
    "    'establishedAffluence_block_26_MAC002966.csv',\n",
    "    'establishedAffluence_block_26_MAC003075.csv',\n",
    "    'establishedAffluence_block_27_MAC003016.csv',\n",
    "    'establishedAffluence_block_27_MAC005235.csv',\n",
    "    'establishedAffluence_block_28_MAC004895.csv',\n",
    "    'establishedAffluence_block_28_MAC005217.csv',\n",
    "    'establishedAffluence_block_30_MAC000274.csv',\n",
    "    'establishedAffluence_block_30_MAC003114.csv',\n",
    "    'establishedAffluence_block_31_MAC001378.csv',\n",
    "    'establishedAffluence_block_32_MAC001433.csv',\n",
    "    'establishedAffluence_block_32_MAC002686.csv',\n",
    "    'establishedAffluence_block_33_MAC000351.csv',\n",
    "    'establishedAffluence_block_33_MAC002099.csv',\n",
    "    'establishedAffluence_block_33_MAC004926.csv',\n",
    "    'establishedAffluence_block_33_MAC004965.csv',\n",
    "    'establishedAffluence_block_34_MAC001452.csv',\n",
    "    'establishedAffluence_block_34_MAC002265.csv',\n",
    "    'establishedAffluence_block_35_MAC001111.csv',\n",
    "    'establishedAffluence_block_37_MAC000782.csv',\n",
    "    'establishedAffluence_block_37_MAC000861.csv',\n",
    "    'establishedAffluence_block_39_MAC001651.csv',\n",
    "    'establishedAffluence_block_39_MAC001905.csv',\n",
    "    'establishedAffluence_block_40_MAC000459.csv',\n",
    "    'establishedAffluence_block_40_MAC005359.csv',\n",
    "    'stretchedSociety_block_100_MAC002775.csv',\n",
    "    'stretchedSociety_block_100_MAC002824.csv',\n",
    "    'stretchedSociety_block_100_MAC002856.csv',\n",
    "    'stretchedSociety_block_100_MAC002898.csv',\n",
    "    'stretchedSociety_block_100_MAC003020.csv',\n",
    "    'stretchedSociety_block_102_MAC003964.csv',\n",
    "    'stretchedSociety_block_102_MAC003980.csv',\n",
    "    'stretchedSociety_block_102_MAC003996.csv',\n",
    "    'stretchedSociety_block_102_MAC004129.csv',\n",
    "    'stretchedSociety_block_104_MAC000090.csv',\n",
    "    'stretchedSociety_block_104_MAC004395.csv',\n",
    "    'stretchedSociety_block_104_MAC004481.csv',\n",
    "    'stretchedSociety_block_105_MAC002054.csv',\n",
    "    'stretchedSociety_block_106_MAC000077.csv',\n",
    "    'stretchedSociety_block_106_MAC000653.csv',\n",
    "    'stretchedSociety_block_106_MAC001460.csv',\n",
    "    'stretchedSociety_block_106_MAC002318.csv',\n",
    "    'stretchedSociety_block_107_MAC001672.csv',\n",
    "    'stretchedSociety_block_107_MAC001673.csv',\n",
    "    'stretchedSociety_block_107_MAC001785.csv',\n",
    "    'stretchedSociety_block_109_MAC000529.csv',\n",
    "    'stretchedSociety_block_109_MAC002196.csv',\n",
    "    'stretchedSociety_block_109_MAC002293.csv',\n",
    "    'stretchedSociety_block_109_MAC005547.csv',\n",
    "    'stretchedSociety_block_110_MAC002175.csv',\n",
    "    'stretchedSociety_block_91_MAC000350.csv',\n",
    "    'stretchedSociety_block_93_MAC000449.csv',\n",
    "    'stretchedSociety_block_93_MAC004547.csv',\n",
    "    'stretchedSociety_block_94_MAC000838.csv',\n",
    "    'stretchedSociety_block_94_MAC000870.csv',\n",
    "    'stretchedSociety_block_94_MAC004366.csv',\n",
    "    'stretchedSociety_block_95_MAC000006.csv',\n",
    "    'stretchedSociety_block_95_MAC000365.csv',\n",
    "    'stretchedSociety_block_95_MAC004066.csv',\n",
    "    'stretchedSociety_block_96_MAC001188.csv',\n",
    "    'stretchedSociety_block_96_MAC001243.csv',\n",
    "    'stretchedSociety_block_97_MAC000696.csv',\n",
    "    'stretchedSociety_block_97_MAC001035.csv',\n",
    "    'stretchedSociety_block_97_MAC001041.csv',\n",
    "    'stretchedSociety_block_98_MAC001062.csv',\n",
    "    'stretchedSociety_block_98_MAC004064.csv',\n",
    "    'stretchedSociety_block_98_MAC004892.csv',\n",
    "    'stretchedSociety_block_98_MAC004934.csv',\n",
    "    'stretchedSociety_block_99_MAC004745.csv',\n",
    "    'stretchedSociety_block_99_MAC004799.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-park",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
