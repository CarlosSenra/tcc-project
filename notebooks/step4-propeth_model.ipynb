{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../EDA/dataframe_model/stretchedSociety_block_109_MAC005547.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['time','Energy_kwh','holiday','month','hour','dayofweek_num']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['time','Energy_kwh','holiday','month','hour','dayofweek_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Função para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# Função para calcular SMAPE\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Preparar os dados\n",
    "df_prophet = df.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = len(df) - 168\n",
    "df_train = df_prophet[:train_size]\n",
    "df_test = df_prophet[train_size:]\n",
    "\n",
    "# Criar e treinar o modelo Prophet\n",
    "start_time = time.time()\n",
    "\n",
    "model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\n",
    "model.add_regressor('holiday')\n",
    "model.add_regressor('month')\n",
    "model.add_regressor('hour')\n",
    "model.add_regressor('dayofweek_num')\n",
    "\n",
    "model.fit(df_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Fazer previsões\n",
    "future = df_test[['ds', 'holiday', 'month', 'hour', 'dayofweek_num']]\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Calcular métricas\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat'].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Salvar resultados em CSV\n",
    "results = pd.DataFrame({\n",
    "    'model': ['Prophet'],\n",
    "    'mae': [mae],\n",
    "    'mape': [mape],\n",
    "    'smape': [smape],\n",
    "    'rmse': [rmse],\n",
    "    'training_time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('prophet_results.csv', index=False)\n",
    "\n",
    "print(\"Resultados salvos em 'prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Função para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Função para calcular SMAPE\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Preparar os dados\n",
    "df_sarimax = df.set_index('time')\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = len(df) - 168\n",
    "df_train = df_sarimax[:train_size]\n",
    "df_test = df_sarimax[train_size:]\n",
    "\n",
    "# Definir variáveis exógenas\n",
    "exog_vars = ['holiday', 'month', 'hour', 'dayofweek_num']\n",
    "\n",
    "# Criar e treinar o modelo SARIMAX\n",
    "start_time = time.time()\n",
    "\n",
    "# Aqui, estamos usando um modelo SARIMAX(1,1,1)(1,1,1,24) como exemplo\n",
    "# Você pode ajustar esses parâmetros conforme necessário\n",
    "model = SARIMAX(df_train['Energy_kwh'], \n",
    "                exog=df_train[exog_vars],\n",
    "                order=(1, 1, 1),\n",
    "                seasonal_order=(1, 1, 1, 24),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Fazer previsões\n",
    "forecast = results.get_forecast(steps=168, exog=df_test[exog_vars])\n",
    "y_pred = forecast.predicted_mean\n",
    "\n",
    "# Calcular métricas\n",
    "y_true = df_test['Energy_kwh'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Salvar resultados em CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'model': ['SARIMAX'],\n",
    "    'mae': [mae],\n",
    "    'mape': [mape],\n",
    "    'smape': [smape],\n",
    "    'rmse': [rmse],\n",
    "    'training_time': [training_time]\n",
    "})\n",
    "\n",
    "results_df.to_csv('sarimax_results.csv', index=False)\n",
    "\n",
    "print(\"Resultados salvos em 'sarimax_results.csv'\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Preparação dos dados\n",
      "                    ds      y  holiday  month  hour  dayofweek_num\n",
      "0  2013-01-01 00:00:00  0.497        1      0     0              0\n",
      "1  2013-01-01 01:00:00  0.314        0      0     1              0\n",
      "2  2013-01-01 02:00:00  0.202        0      0     2              0\n",
      "3  2013-01-01 03:00:00  0.171        0      0     3              0\n",
      "4  2013-01-01 04:00:00  0.185        0      0     4              0\n",
      "Shape dos dados: (10153, 6)\n",
      "\n",
      "Passo 2: Divisão dos dados\n",
      "Shape do conjunto de treino: (9985, 6)\n",
      "Shape do conjunto de teste: (168, 6)\n",
      "\n",
      "Passo 3: Configuração do modelo Neural Prophet\n",
      "\n",
      "Passo 4: Treinamento do modelo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b426c6e1abf4c03bd071fb9bf23ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (157) is too small than the required number                     for the learning rate finder (250). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebc8717156f46efb042430998b26f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7bcddd41cc40ceb6563785463d5b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 129.06 segundos\n",
      "\n",
      "Passo 5: Fazendo previsões\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa27e415087c4d0da63f3cc471ca1c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds      y     yhat1     trend  season_yearly  \\\n",
      "0 2014-02-21 01:00:00  0.555  0.307385  0.334974       0.059196   \n",
      "1 2014-02-21 02:00:00  0.588  0.226512  0.334983       0.059258   \n",
      "2 2014-02-21 03:00:00  0.398  0.195170  0.334993       0.059319   \n",
      "3 2014-02-21 04:00:00  0.163  0.183428  0.335002       0.059380   \n",
      "4 2014-02-21 05:00:00  0.159  0.181712  0.335012       0.059443   \n",
      "\n",
      "   season_weekly  season_daily  future_regressors_additive  \\\n",
      "0      -0.020100     -0.065280                   -0.001405   \n",
      "1      -0.019357     -0.146040                   -0.002332   \n",
      "2      -0.018531     -0.177351                   -0.003258   \n",
      "3      -0.017640     -0.189129                   -0.004185   \n",
      "4      -0.016663     -0.190968                   -0.005112   \n",
      "\n",
      "   future_regressor_dayofweek_num  future_regressor_holiday  \\\n",
      "0                       -0.005474                       0.0   \n",
      "1                       -0.005474                       0.0   \n",
      "2                       -0.005474                       0.0   \n",
      "3                       -0.005474                       0.0   \n",
      "4                       -0.005474                       0.0   \n",
      "\n",
      "   future_regressor_hour  future_regressor_month  \n",
      "0              -0.000927                0.004996  \n",
      "1              -0.001853                0.004996  \n",
      "2              -0.002780                0.004996  \n",
      "3              -0.003707                0.004996  \n",
      "4              -0.004633                0.004996  \n",
      "\n",
      "Passo 6: Cálculo das métricas\n",
      "\n",
      "Passo 7: Salvando resultados\n",
      "\n",
      "Resultados salvos em 'neural_prophet_results.csv'\n",
      "           Model       MAE      RMSE      MAPE      SMAPE  Training_Time\n",
      "0  NeuralProphet  0.119048  0.148566  51.55919  38.307913     129.062095\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Assumindo que df já está definido e contém os dados necessários\n",
    "\n",
    "# Passo 1: Preparação dos dados\n",
    "print(\"Passo 1: Preparação dos dados\")\n",
    "df_model = df[['time', 'Energy_kwh', 'holiday', 'month', 'hour', 'dayofweek_num']].copy()\n",
    "df_model = df_model.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "print(df_model.head())\n",
    "print(f\"Shape dos dados: {df_model.shape}\")\n",
    "\n",
    "# Passo 2: Definir o ponto de divisão para treinamento/teste\n",
    "print(\"\\nPasso 2: Divisão dos dados\")\n",
    "split_point = len(df_model) - 168\n",
    "df_train = df_model[:split_point]\n",
    "df_test = df_model[split_point:]\n",
    "print(f\"Shape do conjunto de treino: {df_train.shape}\")\n",
    "print(f\"Shape do conjunto de teste: {df_test.shape}\")\n",
    "\n",
    "# Passo 3: Configuração do modelo Neural Prophet\n",
    "print(\"\\nPasso 3: Configuração do modelo Neural Prophet\")\n",
    "model = NeuralProphet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Adicionar as covariáveis\n",
    "for regressor in ['holiday', 'month', 'hour', 'dayofweek_num']:\n",
    "    model.add_future_regressor(regressor)\n",
    "\n",
    "# Passo 4: Treinamento do modelo e medição do tempo\n",
    "print(\"\\nPasso 4: Treinamento do modelo\")\n",
    "start_time = time.time()\n",
    "metrics = model.fit(df_train, freq='H')\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Tempo de treinamento: {training_time:.2f} segundos\")\n",
    "\n",
    "# Passo 5: Fazer previsões\n",
    "print(\"\\nPasso 5: Fazendo previsões\")\n",
    "# Usamos df_test diretamente, pois já contém os valores futuros dos regressores\n",
    "forecast = model.predict(df_test)\n",
    "print(forecast.head())\n",
    "\n",
    "# Passo 6: Calcular métricas\n",
    "print(\"\\nPasso 6: Cálculo das métricas\")\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat1'].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "\n",
    "# Passo 7: Salvar resultados em CSV\n",
    "print(\"\\nPasso 7: Salvando resultados\")\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['NeuralProphet'],\n",
    "    'MAE': [mae],\n",
    "    'RMSE': [rmse],\n",
    "    'MAPE': [mape],\n",
    "    'SMAPE': [smape],\n",
    "    'Training_Time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('neural_prophet_results.csv', index=False)\n",
    "\n",
    "print(\"\\nResultados salvos em 'neural_prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as h\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Preparação dos dados\n",
      "                    ds      y  holiday  month  hour  dayofweek_num\n",
      "0  2013-01-01 00:00:00  0.497        1      0     0              0\n",
      "1  2013-01-01 01:00:00  0.314        0      0     1              0\n",
      "2  2013-01-01 02:00:00  0.202        0      0     2              0\n",
      "3  2013-01-01 03:00:00  0.171        0      0     3              0\n",
      "4  2013-01-01 04:00:00  0.185        0      0     4              0\n",
      "Shape dos dados: (10153, 6)\n",
      "\n",
      "Passo 2: Configuração do modelo Neural Prophet\n",
      "\n",
      "Passo 3: Divisão dos dados\n",
      "Shape do conjunto de treino: (9985, 6)\n",
      "Shape do conjunto de teste: (168, 6)\n",
      "\n",
      "Passo 4: Treinamento do modelo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c47a8668b8a4177bedcd4fed149982f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (157) is too small than the required number                     for the learning rate finder (250). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf18b7a7b944fa850a5a4350566707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bab6a442164b76a1fddee44b6eea15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento: 125.41 segundos\n",
      "\n",
      "Passo 5: Criando dataframe futuro e fazendo previsões\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.99% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:983: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  future_dates = pd.date_range(start=last_date, periods=periods + 1, freq=freq)  # An extra in case we include start\n",
      "\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.405% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /home/carlos/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/neuralprophet/df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4ab06f2f23433db0984b44199324b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds     y     yhat1     trend  season_yearly  season_weekly  \\\n",
      "0 2014-02-21 01:00:00  None  0.306050  0.385866       0.006615      -0.021134   \n",
      "1 2014-02-21 02:00:00  None  0.223760  0.385886       0.006683      -0.020446   \n",
      "2 2014-02-21 03:00:00  None  0.192097  0.385906       0.006749      -0.019680   \n",
      "3 2014-02-21 04:00:00  None  0.180905  0.385926       0.006817      -0.018834   \n",
      "4 2014-02-21 05:00:00  None  0.178642  0.385945       0.006884      -0.017909   \n",
      "\n",
      "   season_daily  future_regressors_additive  future_regressor_dayofweek_num  \\\n",
      "0     -0.063405                   -0.001891                       -0.005868   \n",
      "1     -0.145585                   -0.002777                       -0.005868   \n",
      "2     -0.177214                   -0.003664                       -0.005868   \n",
      "3     -0.188453                   -0.004550                       -0.005868   \n",
      "4     -0.190843                   -0.005436                       -0.005868   \n",
      "\n",
      "   future_regressor_holiday  future_regressor_hour  future_regressor_month  \n",
      "0                       0.0              -0.000886                0.004863  \n",
      "1                       0.0              -0.001772                0.004863  \n",
      "2                       0.0              -0.002658                0.004863  \n",
      "3                       0.0              -0.003544                0.004863  \n",
      "4                       0.0              -0.004430                0.004863  \n",
      "\n",
      "Passo 6: Cálculo das métricas\n",
      "\n",
      "Passo 7: Salvando resultados\n",
      "\n",
      "Resultados salvos em 'neural_prophet_results.csv'\n",
      "           Model       MAE      RMSE       MAPE      SMAPE  Training_Time\n",
      "0  NeuralProphet  0.119174  0.148845  51.449813  38.330516     125.410824\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "# Assumindo que df já está definido e contém os dados necessários\n",
    "\n",
    "# Passo 1: Preparação dos dados\n",
    "print(\"Passo 1: Preparação dos dados\")\n",
    "df_model = df[['time', 'Energy_kwh', 'holiday', 'month', 'hour', 'dayofweek_num']].copy()\n",
    "df_model = df_model.rename(columns={'time': 'ds', 'Energy_kwh': 'y'})\n",
    "print(df_model.head())\n",
    "print(f\"Shape dos dados: {df_model.shape}\")\n",
    "\n",
    "# Passo 2: Configuração do modelo Neural Prophet\n",
    "print(\"\\nPasso 2: Configuração do modelo Neural Prophet\")\n",
    "model = NeuralProphet(\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Adicionar as covariáveis\n",
    "for regressor in ['holiday', 'month', 'hour', 'dayofweek_num']:\n",
    "    model.add_future_regressor(regressor)\n",
    "\n",
    "# Passo 3: Divisão dos dados usando split_df\n",
    "print(\"\\nPasso 3: Divisão dos dados\")\n",
    "df_train, df_test = model.split_df(df_model, valid_p=168/len(df_model))\n",
    "print(f\"Shape do conjunto de treino: {df_train.shape}\")\n",
    "print(f\"Shape do conjunto de teste: {df_test.shape}\")\n",
    "\n",
    "# Passo 4: Treinamento do modelo e medição do tempo\n",
    "print(\"\\nPasso 4: Treinamento do modelo\")\n",
    "start_time = time.time()\n",
    "metrics = model.fit(df_train, freq='H')\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Tempo de treinamento: {training_time:.2f} segundos\")\n",
    "\n",
    "# Passo 5: Criar dataframe futuro e fazer previsões\n",
    "print(\"\\nPasso 5: Criando dataframe futuro e fazendo previsões\")\n",
    "future_df = model.make_future_dataframe(df_train, periods=168, regressors_df=df_test)\n",
    "forecast = model.predict(future_df)\n",
    "print(forecast.head())\n",
    "\n",
    "# Passo 6: Calcular métricas\n",
    "print(\"\\nPasso 6: Cálculo das métricas\")\n",
    "y_true = df_test['y'].values\n",
    "y_pred = forecast['yhat1'].values[:168]  # Pegamos apenas as primeiras 168 previsões\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "\n",
    "# Passo 7: Salvar resultados em CSV\n",
    "print(\"\\nPasso 7: Salvando resultados\")\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['NeuralProphet'],\n",
    "    'MAE': [mae],\n",
    "    'RMSE': [rmse],\n",
    "    'MAPE': [mape],\n",
    "    'SMAPE': [smape],\n",
    "    'Training_Time': [training_time]\n",
    "})\n",
    "\n",
    "results.to_csv('neural_prophet_results.csv', index=False)\n",
    "\n",
    "print(\"\\nResultados salvos em 'neural_prophet_results.csv'\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-park",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
